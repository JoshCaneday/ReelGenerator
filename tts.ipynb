{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf15af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flash attention 2 is not installed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import soundfile as sf\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "from TTS.api import TTS\n",
    "\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3368de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "version = \"2\" # Used when specifying output path of audio files, increment as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1375b412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jcan2\\GitHub\\ReelGenerator\\.venv\\Lib\\site-packages\\TTS\\tts\\layers\\xtts\\xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "c:\\Users\\jcan2\\GitHub\\ReelGenerator\\.venv\\Lib\\site-packages\\TTS\\utils\\io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "[\"At a certain point you can't keep blaming your childhood for how you act now.\", 'Yes, your parents messed up.', 'Yes, you grew up in a tough environment.', 'Yes, you learned unhealthy patterns early.', 'All of that shaped you.', \"But it doesn't get to control you forever.\", 'There comes a time when how you treat people is on you.', \"When you're reactions are your choice.\", 'When continuing the cycle becomes your decision, not your pasts.', \"You could understand why you're angry, without taking it out on others.\", 'You could know why you struggle with trust without punishing everyone who tries to get close.', 'You can see where your issues come from, without using them as an excuse.', \"Your trauma explains your behavior, it doesn't excuse it.\", 'At some point you have to stop being a victim of you past and start taking responsibility for your present.', \"What happened to you, wasn't your fault.\", 'What you do now is.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 301.78982400894165\n",
      " > Real-time factor: 4.184482666736988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./audios/ttsAPI2.wav'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=False)\n",
    "\n",
    "# generate speech by cloning a voice using default settings\n",
    "tts.tts_to_file(text=\"At a certain point you can't keep blaming your childhood for how you act now. Yes, your parents messed up. Yes, you grew up in a tough environment. Yes, you learned unhealthy patterns early. All of that shaped you. But it doesn't get to control you forever. There comes a time when how you treat people is on you. When you're reactions are your choice. When continuing the cycle becomes your decision, not your pasts. You could understand why you're angry, without taking it out on others. You could know why you struggle with trust without punishing everyone who tries to get close. You can see where your issues come from, without using them as an excuse. Your trauma explains your behavior, it doesn't excuse it. At some point you have to stop being a victim of you past and start taking responsibility for your present. What happened to you, wasn't your fault. What you do now is.\",\n",
    "                file_path=\"./audios/ttsAPI\" + version + \".wav\",\n",
    "                speaker_wav=\"./voices/longvoice1.wav\",\n",
    "                language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70efc1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./models/XTTS-v2\"  # folder containing config.json, model.pth, speakers_xtts.pth, vocab.json, etc.\n",
    "\n",
    "config = XttsConfig()\n",
    "config.load_json(f\"{MODEL_DIR}/config.json\")\n",
    "\n",
    "xttsModel = Xtts.init_from_config(config)\n",
    "xttsModel.load_checkpoint(config, checkpoint_dir=MODEL_DIR, eval=True)\n",
    "\n",
    "xttsModel = xttsModel.to(device)\n",
    "\n",
    "outputs = xttsModel.synthesize(\n",
    "    \"It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.\",\n",
    "    config,\n",
    "    speaker_wav=\"./voices/longvoice1.wav\",\n",
    "    language=\"en\",\n",
    ")\n",
    "\n",
    "sf.write(\"./audios/ttsSaved\" + version + \".wav\", outputs[\"wav\"], config.audio.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05783ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parlerModel = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-mini-v1\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-mini-v1\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "I've made so many mistakes.\n",
    "I'm completely lost in life.\n",
    "Everything's falling apart.\n",
    "Stop thinking negatively.\n",
    "The past is in the past.\n",
    "The future is in the future.\n",
    "I just need to focus on today.\n",
    "\"\"\"\n",
    "description = \"A burly man's voice is monotone yet warm, deep, inspiring, with a very close recording that almost has no background noise.\"\n",
    "\n",
    "input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "generation = parlerModel.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "audio_arr = generation.cpu().numpy().squeeze()\n",
    "sf.write(\"./audios/parler_tts_out.wav\", audio_arr, parlerModel.config.sampling_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
